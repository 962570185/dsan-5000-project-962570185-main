## Project Proposal:
1. Projectâ€™s objectives


2. Dataset selection
Here I select the clean data for the movie data

3. The tools or libraries
The code will be implemented in Python. The library pandas and numpy will be used to read and process the data. The library scikit-learn will be used to implement the model.

## Code Implementation:

**Read file**
```{python}
import pandas as pd

file_name = '../../data/others/IMDB_Top_250_Movies_ver2.csv'
df=pd.read_csv(file_name)  
df = df.drop(['Unnamed: 0'], axis=1)
print(df.shape)
```

```{python}
df.head()
```

**Preprocess the data**
```{python}
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.feature_extraction.text import CountVectorizer
import numpy as np

# genre
mlb = MultiLabelBinarizer()
df_genres = mlb.fit_transform(df['genre'])
df_genres = pd.DataFrame(df_genres, columns=mlb.classes_)
df = df.drop('genre', axis=1).join(df_genres)

#casts
df['casts'] = df['casts'].apply(lambda x: x.split(','))
df_casts = mlb.fit_transform(df['casts'])
df_casts = pd.DataFrame(df_casts, columns=mlb.classes_)
df = df.drop('casts', axis=1).join(df_casts)

# certificate
# encoder = OneHotEncoder(sparse=False)
# ct = ColumnTransformer([("certificate", encoder, ['certificate'])], remainder='passthrough')
# df_encoded = ct.fit_transform(df)
# df_encoded = pd.DataFrame(df_encoded, columns=ct.get_feature_names_out())
# df = df.drop('certificate', axis=1).join(df_encoded)

# directors
encoder = OneHotEncoder(sparse=False)
ct = ColumnTransformer([("directors", encoder, ['directors'])], remainder='passthrough')
df_encoded = ct.fit_transform(df)
df_encoded = pd.DataFrame(df_encoded, columns=ct.get_feature_names_out())
df = df.drop('directors', axis=1)
df = pd.concat([df, df_encoded], axis=1)


print(df.head())

X = np.array(df)
```


**Dimensionality Reduction with PCA**
1. Apply PCA to record dataset.
```{python}
from sklearn.decomposition import PCA

pca_original = PCA()
pca_original.fit(X)
```

2. Determine the optimal number of principal components to retain.
```{python}
import matplotlib.pyplot as plt

cumulative_variance = np.cumsum(pca_original.explained_variance_ratio_)
n_components = np.argmax(cumulative_variance >= 0.8) + 1

plt.figure(figsize=(8, 4))
plt.plot(np.cumsum(pca_original.explained_variance_ratio_))
plt.xlabel('Number of Components')
plt.ylabel('Cumulative Explained Variance')
plt.title('Explained Variance by Components')
plt.grid(True)
plt.show()
```

3. Visualize the reduced-dimensional data using PCA.
```{python}
import seaborn as sns

pca = PCA(n_components=n_components)
pca.fit(X)
print(pca.explained_variance_ratio_)
print(pca.singular_values_)

principal_components = pca.fit_transform(X)
df2 = pd.DataFrame(data = principal_components)
df3=pd.concat([df2,df['rating']], axis=1)

sns.scatterplot(data=df2, x=0, y=1,hue=df["rating"]) 
plt.show()

sns.pairplot(data=df3,hue="rating") 
plt.show()
```


**Dimensionality Reduction with t-SNE**
1. Implement t-SNE on the same dataset.
```{python}
from sklearn.manifold import TSNE
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
data_standardized = scaler.fit_transform(X)

perplexities = [5, 30, 50, 100] 
tsne_results = []

for perplexity in perplexities:
    tsne = TSNE(n_components=2, perplexity=perplexity, random_state=0)
    tsne_result = tsne.fit_transform(data_standardized)
    tsne_results.append(tsne_result)

 
fig, axes = plt.subplots(1, len(perplexities) + 1, figsize=(15, 7))
for i, tsne_result in enumerate(tsne_results):
    axes[i + 1].scatter(tsne_result[:, 0], tsne_result[:, 1], c=df["rating"])
    axes[i + 1].set_title(f't-SNE with Perplexity = {perplexities[i]}')
plt.show()
```
2. Explore different perplexity values and their impact.

3. Visualize the t-SNE output to reveal patterns and clusters.


Evaluation and Comparison
Evaluate the effectiveness of PCA and t-SNE in terms of preserving data structure and information.
Compare the visualization capabilities of PCA and t-SNE.
Discuss the trade-offs and scenarios where one technique may outperform the other.

## Project Report:
A comprehensive project report detailing the steps taken, results obtained, and your analysis.
Include visualizations, comparisons, and insights gained from the dimensionality reduction techniques.